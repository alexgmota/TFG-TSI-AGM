{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning: Endoscopy segmentation.\n",
    "[Dataset](https://www.kaggle.com/datasets/newslab/cholecseg8k?resource=download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import random\n",
    "from Uformer import modelIdentity\n",
    "from losses import losses\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available(), torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 33\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the device to be used for training and evaluation\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# determine if we will be pinning memory during data loading\n",
    "PIN_MEMORY = True if DEVICE == \"cuda\" else False\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "# initialize learning rate, number of epochs to train for, and the\n",
    "# batch size\n",
    "INIT_LR = 8e-5\n",
    "WEIGHT_DECAY = 1e-8\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "# define the input image dimensions\n",
    "INPUT_IMAGE_WIDTH = 128\n",
    "INPUT_IMAGE_HEIGHT = 128"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DATASET_PATH = glob(f'../../car-segmentation/images/*.png')\n",
    "MASK_DATASET_PATH  = glob(f'../../car-segmentation/masks/*.png')\n",
    "N = len(IMAGE_DATASET_PATH)\n",
    "assert len(IMAGE_DATASET_PATH) == len(MASK_DATASET_PATH)\n",
    "\n",
    "print(f'Number of samples: {str(len(MASK_DATASET_PATH))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/IdeaKing/11cf5e146d23c5bb219ba3508cca89ec\n",
    "def resize_with_pad(image: np.array, \n",
    "                    new_shape, \n",
    "                    padding_color = (0, 0, 0)) -> np.array:\n",
    "    \"\"\"Maintains aspect ratio and resizes with padding.\n",
    "    Params:\n",
    "        image: Image to be resized.\n",
    "        new_shape: Expected (width, height) of new image.\n",
    "        padding_color: Tuple in BGR of padding color\n",
    "    Returns:\n",
    "        image: Resized image with padding\n",
    "    \"\"\"\n",
    "    original_shape = (image.shape[1], image.shape[0])\n",
    "    ratio = float(max(new_shape))/max(original_shape)\n",
    "    new_size = tuple([int(x*ratio) for x in original_shape])\n",
    "    image = cv2.resize(image, new_size, interpolation=cv2.INTER_NEAREST)\n",
    "    delta_w = new_shape[0] - new_size[0]\n",
    "    delta_h = new_shape[1] - new_size[1]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=padding_color)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes=None, dtype=\"float32\"):\n",
    "\ty = np.array(y, dtype=\"int\")\n",
    "\tinput_shape = y.shape\n",
    "\n",
    "\t# Shrink the last dimension if the shape is (..., 1).\n",
    "\tif input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "\t\tinput_shape = tuple(input_shape[:-1])\n",
    "\n",
    "\ty = y.reshape(-1)\n",
    "\tif not num_classes:\n",
    "\t\tnum_classes = np.max(y) + 1\n",
    "\tn = y.shape[0]\n",
    "\tcategorical = np.zeros((n, num_classes), dtype=dtype)\n",
    "\tcategorical[np.arange(n), y] = 1\n",
    "\toutput_shape = input_shape + (num_classes,)\n",
    "\tcategorical = np.reshape(categorical, output_shape)\n",
    "\treturn categorical\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "\tdef __init__(self, imagePaths, maskPaths):\n",
    "\t\t# store the image and mask filepaths, and augmentation\n",
    "\t\t# transforms\n",
    "\t\tself.imagePaths = imagePaths\n",
    "\t\tself.maskPaths = maskPaths\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\t# return the number of total samples contained in the dataset\n",
    "\t\treturn len(self.imagePaths)\n",
    "\t\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timagePath = self.imagePaths[idx]\n",
    "\n",
    "\t\timage = cv2.imread(imagePath)\n",
    "\t\timage = resize_with_pad(image, (INPUT_IMAGE_WIDTH, INPUT_IMAGE_HEIGHT))\n",
    "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\t\timage = image / 255\n",
    "\t\timage = torch.from_numpy(np.float32(image))\n",
    "\t\timage = image.permute(2,0,1)\n",
    "\n",
    "\t\tmask = cv2.imread(self.maskPaths[idx])\n",
    "\t\tmask = resize_with_pad(mask, (INPUT_IMAGE_WIDTH, INPUT_IMAGE_HEIGHT), (0, 0, 0))\n",
    "\t\tmask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "\t\tmask = np.expand_dims(mask, axis=-1)\n",
    "\t\tmask = to_categorical(mask)\n",
    "\t\tmask = torch.from_numpy(np.float32(mask))\n",
    "\t\tmask = mask.permute(2,0,1)\n",
    "\n",
    "\t\tassert image.shape == (3, INPUT_IMAGE_HEIGHT, INPUT_IMAGE_WIDTH), f\"Bad image shape {image.shape}\"\n",
    "\t\tassert mask.shape == (NUM_CLASSES, INPUT_IMAGE_HEIGHT, INPUT_IMAGE_WIDTH), f\"Bad mask shape {mask.shape}\"\n",
    "\n",
    "\t\t# return a tuple of the image and its mask\n",
    "\t\treturn image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uformer = modelIdentity.Uformer(img_size=INPUT_IMAGE_HEIGHT,in_chans=NUM_CLASSES, embed_dim=16, win_size=8, token_projection='linear', token_mlp='leff',modulator=True)\n",
    "trainImages, testImages, trainMasks, testMasks = train_test_split(IMAGE_DATASET_PATH, MASK_DATASET_PATH, test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transformations\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# create the train and test datasets\n",
    "trainDS = SegmentationDataset(imagePaths=trainImages, maskPaths=trainMasks)\n",
    "testDS = SegmentationDataset(imagePaths=testImages, maskPaths=testMasks)\n",
    "print(f\"[INFO] found {len(trainDS)} examples in the training set...\")\n",
    "print(f\"[INFO] found {len(testDS)} examples in the test set...\")\n",
    "# create the training and test data loaders\n",
    "num_workers = 4\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "\n",
    "trainLoader = DataLoader(\n",
    "\ttrainDS, \n",
    "\tshuffle=True,\n",
    "\tbatch_size=BATCH_SIZE, \n",
    "\tpin_memory=PIN_MEMORY,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")\n",
    "testLoader = DataLoader(\n",
    "\ttestDS, shuffle=False,\n",
    "\tbatch_size=BATCH_SIZE, \n",
    "\tpin_memory=PIN_MEMORY,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uformer = uformer.to(DEVICE)\n",
    "softmax = torch.nn.Softmax(1)\n",
    "# initialize loss function and optimizer\n",
    "lossFunc = losses.TverskyLoss().cuda()\n",
    "opt = torch.optim.Adam(uformer.parameters(), lr=INIT_LR, betas=(0.9, 0.999),eps=1e-8, weight_decay=WEIGHT_DECAY)\n",
    "iouMetric = losses.MeanIoU().cuda()\n",
    "gdlMetric = losses.DiceCoeficient().cuda()\n",
    "\n",
    "# calculate steps per epoch for training and test set\n",
    "trainSteps = len(trainDS) // BATCH_SIZE + 1\n",
    "testSteps = len(testDS) // BATCH_SIZE + 1\n",
    "\n",
    "scheduler = CosineAnnealingLR(opt, T_max=trainSteps*NUM_EPOCHS)\n",
    "\n",
    "# initialize a dictionary to store training history\n",
    "H = {\"train_loss\": [], \"test_loss\": [], \"train_IoU\": [], \"test_IoU\": [],\"train_DC\": [], \"test_DC\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestIoU = 0\n",
    "# loop over epochs\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()\n",
    "for e in range(NUM_EPOCHS):\n",
    "\t# torch.cuda.empty_cache()\n",
    "\t# set the model in training mode\n",
    "\tuformer.train()\n",
    "\t# initialize the total training and validation loss\n",
    "\ttotalTrainLoss = 0\n",
    "\ttotalTestLoss = 0\n",
    "\n",
    "\ttotalTrainIoU = 0\n",
    "\ttotalTestIoU = 0\n",
    "\ttotalTrainDC = 0\n",
    "\ttotalTestDC = 0\n",
    "\t# loop over the training set\n",
    "\tfor i, (x, y) in enumerate(tqdm(trainLoader)):\n",
    "\t\t# send the input to the device\n",
    "\t\tx, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\t\t# perform a forward pass and calculate the training loss\n",
    "\t\tpred = uformer(x)\n",
    "\t\tassert pred.shape == y.shape, f\"{pred.shape} != {y.shape}\" # B, C, H, W\n",
    "\t\tpred = softmax(pred)\n",
    "\t\tloss = lossFunc(pred, y)\n",
    "\t\t# first, zero out any previously accumulated gradients, then\n",
    "\t\t# perform backpropagation, and then update model parameters\n",
    "\t\topt.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\topt.step()\n",
    "\t\tscheduler.step()\n",
    "\t\t# add the loss to the total training loss so far\n",
    "\t\ttotalTrainLoss += loss\n",
    "\t\ttotalTrainIoU += iouMetric(pred, y)\n",
    "\t\ttotalTrainDC += gdlMetric(pred, y)\n",
    "\t# switch off autograd\n",
    "\twith torch.no_grad():\n",
    "\t\t# set the model in evaluation mode\n",
    "\t\tuformer.eval()\n",
    "\t\t# loop over the validation set\n",
    "\t\tfor (x, y) in testLoader:\n",
    "\t\t\t# send the input to the device\n",
    "\t\t\t(x, y) = (x.to(DEVICE), y.to(DEVICE))\n",
    "\t\t\t# make the predictions and calculate the validation loss\n",
    "\t\t\tpred = uformer(x)\n",
    "\t\t\tassert pred.shape == y.shape, f\"{pred.shape} != {y.shape}\" # B, C, H, W\n",
    "\t\t\tpred = softmax(pred)\n",
    "\t\t\ttotalTestLoss += lossFunc(pred, y)\n",
    "\t\t\ttotalTestIoU += iouMetric(pred, y)\n",
    "\t\t\ttotalTestDC += gdlMetric(pred, y)\n",
    "\t\t\t\n",
    "\t# calculate the average training and validation loss\n",
    "\tavgTrainLoss = totalTrainLoss / trainSteps\n",
    "\tavgTestLoss = totalTestLoss / testSteps\n",
    "\n",
    "\tavgTrainIoU = totalTrainIoU / trainSteps\n",
    "\tavgTestIoU = totalTestIoU / testSteps\n",
    "\tavgTrainDC = totalTrainDC / trainSteps\n",
    "\tavgTestDC = totalTestDC / testSteps\n",
    "\t# update our training history\n",
    "\tH[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "\tH[\"test_loss\"].append(avgTestLoss.cpu().detach().numpy())\n",
    "\n",
    "\tH[\"train_IoU\"].append(avgTrainIoU.cpu().detach().numpy())\n",
    "\tH[\"test_IoU\"].append(avgTestIoU.cpu().detach().numpy())\n",
    "\tH[\"train_DC\"].append(avgTrainDC.cpu().detach().numpy())\n",
    "\tH[\"test_DC\"].append(avgTestDC.cpu().detach().numpy())\n",
    "\n",
    "\t# print the model training and validation information\n",
    "\tprint(\"[INFO] EPOCH: {}/{}\".format(e + 1, NUM_EPOCHS))\n",
    "\tprint(f\"Train loss: {avgTrainLoss:.6f}, Test loss: {avgTestLoss:.4f}, \" + \n",
    "       f\"Train IoU: {avgTrainIoU:.4f}, Test IoU: {avgTestIoU:.4f}, Train Dice: {avgTrainDC:.4f}, Test Dice: {avgTestDC:.4f}\")\n",
    "\t\n",
    "\tif avgTestIoU > bestIoU:\n",
    "\t\tbestIoU = avgTestIoU\n",
    "\t\ttorch.save(uformer.state_dict(), '../models/uformeridentity_tversky_car_seg.pth')\n",
    "\t\tprint('Best IoU improved. Model saved.')\n",
    "\t\t\n",
    "# display the total time needed to perform the training\n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))\n",
    "print(f'Best IoU is: {bestIoU:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(H['train_loss'])\n",
    "plt.plot(H['test_loss'], linestyle='dotted')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(H['train_IoU'])\n",
    "plt.plot(H['test_IoU'], linestyle='dotted')\n",
    "plt.plot(H['train_DC'])\n",
    "plt.plot(H['test_DC'], linestyle='dotted')\n",
    "plt.title('Model metrics')\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['train IoU', 'val IoU', 'train dice', 'val_dice'], loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, image):\n",
    "\timage = torch.Tensor(image).permute((2, 0, 1)).to(DEVICE)\n",
    "\timage = torch.unsqueeze(image, 0)\n",
    "\t# set model to evaluation mode\n",
    "\tmodel.eval()\n",
    "\t# turn off gradient tracking\n",
    "\twith torch.no_grad():\n",
    "\t\tpredMask = model(image)\n",
    "\t\tpredMask = softmax(predMask)\n",
    "\t\tpredMask = torch.squeeze(predMask, 0)\n",
    "\t\tpredMask = predMask.permute((1, 2, 0))\n",
    "\t\tpredMask = predMask.cpu().detach().numpy()\n",
    "\t\tpredMask = np.argmax(predMask, axis=-1)\n",
    "\t\tpredMask = np.expand_dims(predMask, axis=-1)\n",
    "\t\t# filter out the weak predictions and convert them to integers\n",
    "\t\treturn predMask.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredImg(image_path):     \n",
    "    image = cv2.imread(image_path)\n",
    "    image = image[10:-10, 120:-120,:]\n",
    "    image = resize_with_pad(image, (INPUT_IMAGE_WIDTH, INPUT_IMAGE_HEIGHT))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = image / 255\n",
    "    return image\n",
    "\n",
    "def getPredMask(mask_path):\n",
    "    mask = cv2.imread(mask_path)\n",
    "    # mask = mask[10:-10, 120:-120,:]\n",
    "    mask = resize_with_pad(mask, (INPUT_IMAGE_WIDTH, INPUT_IMAGE_HEIGHT), (0, 0, 0))\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    mask = to_categorical(mask)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(3):    \n",
    "\n",
    "    idx = random.randint(0, len(testImages) -1)\n",
    "    img = getPredImg(testImages[idx])\n",
    "    mask = getPredMask(testMasks[idx])\n",
    "    \n",
    "    plt.subplot(331 + 3*i)\n",
    "    plt.imshow(img)\n",
    "    plt.title('Image')\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    mask = np.argmax(mask, axis=-1)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    plt.subplot(332 + 3*i)\n",
    "    plt.imshow(mask, cmap='magma', norm=plt.Normalize(vmin=0, vmax=NUM_CLASSES-1))\n",
    "    plt.title('Mask')\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    pred = make_prediction(uformer, img)\n",
    "    plt.subplot(333 + 3*i)\n",
    "    plt.imshow(pred, cmap='magma', norm=plt.Normalize(vmin=0, vmax=NUM_CLASSES-1))\n",
    "    plt.title('Prediction')\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --- \n",
    " TFG - Alejandro García Mota"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f011f267c79147290789ae68e632b5c2d498cf08b7b2ac60d440d7e076e68725"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
